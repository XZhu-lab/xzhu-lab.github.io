<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Welcome to PRIDE Lab | PRIDE</title>
<link rel="shortcut icon" href="https://xzhu-lab.github.io/favicon.ico?v=1756297948884">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://xzhu-lab.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Welcome to PRIDE Lab | PRIDE - Atom Feed" href="https://xzhu-lab.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="Polyu Remote sensing Intelligence for Dynamic Earth (PRIDE) lab is led by Dr. Xiaolin Zhu. PRIDE research interests lie ..." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://xzhu-lab.github.io">
  <img class="avatar" src="https://xzhu-lab.github.io/images/avatar.png?v=1756297948884" alt="">
  </a>
  <h1 class="site-title">
    PRIDE
  </h1>
  <p class="site-description">
    Polyu remote sensing intelligence for dynamic Earth (Pride)
  </p>
  <div class="menu-container">
    
      
        <a href="https://xzhu-lab.github.io/post/home" class="menu">
          Home
        </a>
      
    
      
        <a href="https://xzhu-lab.github.io/post/pi-information" class="menu">
          PI-Information
        </a>
      
    
      
        <a href="https://xzhu-lab.github.io/post/group-members" class="menu">
          Group members
        </a>
      
    
      
        <a href="https://xzhu-lab.github.io/post/selected-research-topics" class="menu">
          Research
        </a>
      
    
      
        <a href="https://xzhu-lab.github.io/post/research" class="menu">
          Publications
        </a>
      
    
      
        <a href="https://xzhu-lab.github.io/post/open-source-code" class="menu">
          Open-Source Code
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Welcome to PRIDE Lab
            </h2>
            <div class="post-info">
              <span>
                2024-05-22
              </span>
              <span>
                7 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content" v-pre>
                <p>Polyu Remote sensing Intelligence for Dynamic Earth (<strong>PRIDE</strong>) lab is led by <strong>Dr. Xiaolin Zhu</strong>. PRIDE research interests lie in the development of remote sensing based geospatial intelligence, and applications of such intelligent technologies to characterize dynamic Earth processes, understand the problems of environmental changes and seek solutions for a sustainable Earth. Research areas in PRIDE lab include satellite images processing, data fusion, time-series data analysis, nighttime light remote sensing, image classification, change detection, vegetation and urban remote sensing. Research in PRIDE was funded by RGC (ECS, GRF) and NSFC China's Excellent Young Scientists Fund (<strong>国家自然基金委优青(港澳)</strong>).</p>
<br>
<h1 id="recruitment">RECRUITMENT</h1>
<p><strong><span style="color: darkred;">Pride lab invites outstanding students and researchers to join</span></strong></p>
<ul>
<li>PhD scholarship:  <a href="https://www.polyu.edu.hk/gs/prospective-students/hkpfs/">https://www.polyu.edu.hk/gs/prospective-students/hkpfs/</a></li>
<li>Master programme: <a href="https://www.polyu.edu.hk/lsgi/study/taught-postgraduate-programmes/">https://www.polyu.edu.hk/lsgi/study/taught-postgraduate-programmes/</a></li>
<li>Postdoc and Research Assistant positions: Please contact Dr. Xiaolin Zhu</li>
</ul>
<br>
<h1 id="news">NEWS</h1>
<ul>
<li>
<p><strong>17 June 2025</strong>: Our lab published a new paper in <em><strong>Remote Sensing of Environment</strong></em> : RESTORE-DiT: Reliable satellite image time series reconstruction by multimodal sequential diffusion transformer. <a href="https://doi.org/10.1016/j.rse.2025.114872">https://doi.org/10.1016/j.rse.2025.114872</a></p>
</li>
<li>
<p><strong>16 June 2025</strong>: Our lab published a new paper in <em><strong>Remote Sensing of Environment</strong></em> : A cloud-regulated land surface warming model to reconstruct daytime surface temperatures under cloudy conditions. <a href="https://doi.org/10.1016/j.rse.2025.114873">https://doi.org/10.1016/j.rse.2025.114873</a></p>
</li>
<li>
<p><strong>9 May 2025</strong>: Prof. Zhu joined the Editorial Board of <em><strong>Remote Sensing of Environment (RSE)</strong></em>, a top journal publishes on terrestrial, oceanic and atmospheric sensing.</p>
</li>
<li>
<p><strong>12 February 2025</strong>: Our lab published a new paper in <em><strong>Remote Sensing of Environment</strong></em> : Spectrotemporal fusion: Generation of frequent hyperspectral satellite imagery. <a href="https://doi.org/10.1016/j.rse.2025.114639">https://doi.org/10.1016/j.rse.2025.114639</a></p>
</li>
<li>
<p><strong>16 December 2024</strong>: Our lab published a new paper in <em><strong>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</strong></em>: CutMix-CD: Advancing Semi-Supervised Change Detection via Mixed Sample Consistency. <a href="https://doi.org/10.1109/TGRS.2024.3520630">https://doi.org/10.1109/TGRS.2024.3520630</a></p>
</li>
<li>
<p><strong>6 December 2024</strong>: Our lab published a new paper in <em><strong>Remote Sensing of Environment</strong></em>  that develops an Automatic SAR-based rapeseed mapping in all terrain and weather conditions using dual-aspect Sentinel-1 time series. <a href="https://doi.org/10.1016/j.rse.2024.114567">https://doi.org/10.1016/j.rse.2024.114567</a></p>
</li>
<li>
<p><strong>2 December 2024</strong>: Our lab published a new paper in <em><strong>Remote Sensing of Environment</strong></em> , this paper proposed a novel entity-based image analysis (EBIA) strategy that can map the complete footprint of rural settlements from Landsat images. <a href="https://doi.org/10.1016/j.rse.2024.114549">https://doi.org/10.1016/j.rse.2024.114549</a></p>
</li>
<li>
<p><strong>31 October 2024</strong>: Our lab published a new paper in <em><strong>Remote Sensing of Environment</strong></em> that develops a novel size-adaptive object mapper (OptiSAR-POM)  to map individual ponds using Sentinel-1/2 time series. <a href="https://doi.org/10.1016/j.rse.2024.114484">https://doi.org/10.1016/j.rse.2024.114484</a></p>
</li>
<li>
<p><strong>15 May 2024</strong>: Our lab published a new paper in <em><strong>Remote Sensing of Environment</strong></em> address the scale gap issue present in downscaling of geostationary meteorological satellite surface temperature images:   <a href="https://www.sciencedirect.com/science/article/pii/S0034425724001524">https://www.sciencedirect.com/science/article/pii/S0034425724001524</a></p>
</li>
<li>
<p><strong>8 June 2023</strong>: Our lab published a new paper in <em><strong>Remote Sensing of Environment</strong></em> to remove clouds on daily nighttime light images:   <a href="https://www.sciencedirect.com/science/article/pii/S0034425723002092">https://www.sciencedirect.com/science/article/pii/S0034425723002092</a></p>
</li>
<li>
<p><strong>29 November 2022</strong>: Our lab published a new paper in <em><strong>Remote Sensing of Environment</strong></em> to map paddy fields in cloudy areas with a newly designed index from SAR time series: <a href="https://doi.org/10.1016/j.rse.2022.113374">https://doi.org/10.1016/j.rse.2022.113374</a></p>
</li>
<li>
<p><strong>24 March 2022</strong>:  Our lab published a new paper that proposed a new method to assess performance of data fusion from multiple aspects in <em><strong>Remote Sensing of Environment</strong></em>: <a href="https://www.sciencedirect.com/science/article/pii/S003442572200116X">https://www.sciencedirect.com/science/article/pii/S003442572200116X</a>. The code of this method can be downloaded from <a href="https://github.com/XZhu-lab/Fusion-accuracy-assessment">https://github.com/XZhu-lab/Fusion-accuracy-assessment</a></p>
</li>
<li>
<p><strong>1 March 2022</strong>: Our PhD student Miss Xiaoyue Tan won the <strong>first-place</strong> in the AAG Student Honors Paper Competition: <a href="https://www.polyu.edu.hk/lsgi/news-and-events/news/2022/0302-lsgi-phd-student-won-the-aag-student-honors-paper-competition/">https://www.polyu.edu.hk/lsgi/news-and-events/news/2022/0302-lsgi-phd-student-won-the-aag-student-honors-paper-competition/</a></p>
</li>
<li>
<p><strong>15 December 2021</strong>: Our lab published a new paper in <em><strong>Remote Sensing of Environment</strong></em> to explain the mechanism of angular effects of nighttime light observations from space:<a href="https://www.sciencedirect.com/science/article/pii/S003442572100554X">https://www.sciencedirect.com/science/article/pii/S003442572100554X</a></p>
</li>
<li>
<p><strong>5 October 2021</strong>: Dr. Zhu received <strong>Dean's Awards</strong> for Outstanding Young Researchers 2021: <a href="https://www.polyu.edu.hk/fce/eBulletin/public/issue131/content131/#ra03">https://www.polyu.edu.hk/fce/eBulletin/public/issue131/content131/#ra03</a></p>
</li>
<li>
<p><strong>14 August 2021</strong>: Our lab published a new paper that investigated how to smooth satellite VI time series for accurately detecting vegetation phenology on <em><strong>ISPRS Journal of Photogrammetry and Remote Sensing</strong></em>: <a href="https://www.sciencedirect.com/science/article/pii/S0924271621002033">https://www.sciencedirect.com/science/article/pii/S0924271621002033</a></p>
</li>
<li>
<p><strong>26 January 2021</strong>: We collaborated with researchers from UConn to develop a meso-scale mathematical model to assess the effectiveness of social distance on the COVID-19 transmission across townships. This model was published in IJGIS: <a href="https://www.tandfonline.com/doi/full/10.1080/13658816.2021.1873999">https://www.tandfonline.com/doi/full/10.1080/13658816.2021.1873999</a> and reported by Uconn Today: <a href="https://today.uconn.edu/2021/01/uconn-researcher-develops-town-level-model-for-covid-19-in-connecticut/">https://today.uconn.edu/2021/01/uconn-researcher-develops-town-level-model-for-covid-19-in-connecticut/</a></p>
</li>
<li>
<p><strong>4 December 2020</strong>: Dr. Zhu joined the Editorial Board of <em><strong>National Remote Sensing Bulletin (遥感学报)</strong></em>. Journal of Remote Sensing is a top journal in the field of remote sensing in China. It publishes research articles in either Chinese or English: <a href="https://hgs.publish.founderss.cn/homeNav?lang=en">https://hgs.publish.founderss.cn/homeNav?lang=en</a></p>
</li>
<li>
<p><strong>22 September 2020</strong>: Dr. Zhu received <strong>China's Excellent Young Scientists Fund</strong>: <a href="https://www.polyu.edu.hk/en/media/media-releases/2020/0922_four-polyu-young-researchers-receive-china-excellent-young-scientists-fund-2020/">https://www.polyu.edu.hk/en/media/media-releases/2020/0922_four-polyu-young-researchers-receive-china-excellent-young-scientists-fund-2020/</a></p>
</li>
<li>
<p><strong>7 September 2020</strong>: Dr. Zhu joined the Editorial Board of <em><strong>Science of Remote Sensing</strong></em>. Science of Remote Sensing is part of the  <em><strong>Remote Sensing of Environment</strong></em> family of journals. This journal focuses on publishing high impact science and applications using state-of-the-art remote sensing techniques: <a href="https://www.sciencedirect.com/journal/science-of-remote-sensing/about/editorial-board">https://www.sciencedirect.com/journal/science-of-remote-sensing/about/editorial-board</a></p>
</li>
<li>
<p><strong>29 August 2020</strong>: Our lab published a new paper that investigated the impact of urbanization on winter wheat spring phenology on <em><strong>Agricultural and Forest Meteorology</strong></em>. The paper can be downloaded from <a href="https://www.sciencedirect.com/science/article/pii/S0168192320302550">https://www.sciencedirect.com/science/article/pii/S0168192320302550</a></p>
</li>
<li>
<p><strong>2 April 2020</strong>: Python code of NSPI time series algorithm and a python package including all codes needed for automatically reconstructing high-quality time-series data are available: <a href="https://xzhu-lab.github.io/post/open-source-code/">https://xzhu-lab.github.io/post/open-source-code/</a></p>
</li>
<li>
<p><strong>28 May 2019</strong>: The Matlab code of SEAM algorithm for adjusting blooming effects in DMSP nighttime light images is available: <a href="https://xzhu-lab.github.io/post/open-source-code/">https://xzhu-lab.github.io/post/open-source-code/</a></p>
</li>
<li>
<p><strong>1 June 2018</strong>: The new cloud detection method was reported by NASA: <a href="https://landsat.gsfc.nasa.gov/article/data-record-for-tropical-forest-monitoring-extended-with-new-cloud-detection-method/">https://landsat.gsfc.nasa.gov/article/data-record-for-tropical-forest-monitoring-extended-with-new-cloud-detection-method/</a>. This method was recently published in Remote Sensing of Environment: <a href="https://doi.org/10.1016/j.rse.2018.05.024">https://doi.org/10.1016/j.rse.2018.05.024</a></p>
</li>
</ul>
<!-- more -->

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#recruitment">RECRUITMENT</a></li>
<li><a href="#news">NEWS</a></li>
</ul>

              </div>
            </div>
          </article>
        </div>

        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://xzhu-lab.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
